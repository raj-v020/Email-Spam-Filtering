{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1vNqjmEl4eSn9tL1blos5e15KhHzt6HUb","authorship_tag":"ABX9TyOxd43dvk4Lu3bam4w67vop"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Wy1-jrEbl9YS"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import nltk\n","from math import log\n","from nltk.corpus import stopwords\n","from nltk import PorterStemmer as Stemmer\n","import re"]},{"cell_type":"code","source":["nltk.download('stopwords')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EDKhqCWHoPpU","executionInfo":{"status":"ok","timestamp":1725376649352,"user_tz":-330,"elapsed":8,"user":{"displayName":"Raj Vishwakarma","userId":"08775079886412699309"}},"outputId":"e0d5309d-b287-4b91-a1e3-04adefe0f210"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["import zipfile\n","\n","zip_ref = zipfile.ZipFile('/content/drive/MyDrive/data.zip', 'r')\n","zip_ref.extractall('/content/dataset')\n","zip_ref.close()"],"metadata":{"id":"q2QKP9kTJIYm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_index = 1\n","target_index = 0"],"metadata":{"id":"WIcMvrvO5Iht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def count_words(message):\n","  counts = {}\n","  for word in message:\n","    if word in counts:\n","      counts[word] += 1\n","    else:\n","      counts[word] = 1\n","  return counts"],"metadata":{"id":"-hmBZTN0iq_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_kaggle(split):\n","  data = pd.read_csv('/content/dataset/emails.csv').to_numpy()\n","  np.random.shuffle(data)\n","  data_split = int(len(data)*split)\n","  train_data, test_data = (data[:data_split], data[data_split:])\n","  total_prob_ham = len([d for d in data if d[target_index] == 0])/len(data)\n","  total_prob_spam = 1 - total_prob_ham\n","  return train_data, test_data, total_prob_ham, total_prob_spam"],"metadata":{"id":"AhInW-Mb4Aoh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_enron(split):\n","  data = pd.read_csv('/content/dataset/enron_spam_data.csv')\n","  data = data[['Subject', 'Message', 'Spam/Ham']] #Select only these columns\n","  data = data[data['Message'].notna() & data['Subject'].notna() & data['Spam/Ham'].notna()] #filter out NaN data\n","  data['Mail'] = data['Subject'] + ' ' + data['Message'] #Combine Subject with Mail Message\n","  data['Spam/Ham'] = data['Spam/Ham'].replace(['ham', 'spam'], [0, 1]) #Convert text labels to numbers\n","  data = data[['Mail', 'Spam/Ham']] #Select only these columns\n","  data.columns = ['Message', 'Spam/Ham'] #Rename columns\n","  data = data.to_numpy()\n","  np.random.shuffle(data)\n","  data_split = int(len(data)*split)\n","  train_data, test_data = (data[:data_split], data[data_split:])\n","  total_prob_ham = len([d for d in data if d[target_index] == 0])/len(data)\n","  total_prob_spam = 1 - total_prob_ham\n","  return train_data, test_data, total_prob_ham, total_prob_spam"],"metadata":{"id":"ob5sTyLW5Ukg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def process_mix(split):\n","  data = pd.read_csv('/content/dataset/data.csv').to_numpy()\n","  np.random.shuffle(data)\n","  data_split = int(len(data)*split)\n","  train_data, test_data = (data[:data_split], data[data_split:])\n","  total_prob_ham = len([d for d in data if d[target_index] == 0])/len(data)\n","  total_prob_spam = 1 - total_prob_ham\n","  return train_data, test_data, total_prob_ham, total_prob_spam"],"metadata":{"id":"J_luBPy1q0Xt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NB_Classifier(object):\n","\n","    def __init__(self, train_data, test_data):\n","        self.hams = [h[feature_index] for h in train_data if h[target_index] == 0]\n","        self.spams = [s[feature_index] for s in train_data if s[target_index] == 1]\n","        self.stop_words = stopwords.words('english')\n","        self.words = {}\n","        self.get_words(self.hams + self.spams)\n","\n","    def get_words(self, docs):\n","        word_index = 0\n","        for doc in docs:\n","            tokens = self.tokenize(doc)\n","            for token in tokens:\n","                if token not in self.words:\n","                    self.words[token] = word_index\n","                    word_index += 1\n","\n","    def tfidf(self, docs):\n","        num_docs = len(docs)\n","        num_words = len(self.words)\n","        F = np.zeros((num_docs, num_words))\n","\n","        for i, doc in enumerate(docs):\n","            tokens = self.tokenize(doc)\n","            token_counts = count_words(tokens)\n","            for token, count in token_counts.items():\n","                if token in self.words:\n","                    j = self.words[token]\n","                    if(count != 0):\n","                      F[i, j] = 1\n","        return F\n","\n","    def train(self):\n","      ham_size = len(self.hams)\n","      spam_size = len(self.spams)\n","\n","      self.ham_probs = (self.tfidf(self.hams).sum(axis = 0) + 1) / (ham_size + 2)\n","      self.spam_probs = (self.tfidf(self.spams).sum(axis = 0) + 1) / (spam_size + 2)\n","\n","\n","    def test(self):\n","      confusion_mat = np.zeros((2, 2), dtype=int)\n","      for mail in test_data:\n","        prediction = self.classify_mail(mail[feature_index])\n","        target = mail[target_index]\n","        if prediction == target:\n","          confusion_mat[prediction][prediction] += 1\n","        else:\n","          confusion_mat[prediction][target] += 1\n","\n","      print(confusion_mat)\n","\n","    def classify_mail(self, mail):\n","\n","      mail = self.tokenize(mail)\n","      prob_ham = log(total_prob_ham)\n","      prob_spam = log(total_prob_spam)\n","\n","      for word in mail:\n","        if word in self.words:\n","          index = self.words[word]\n","          prob_ham = prob_ham + log(self.ham_probs[index])\n","          prob_spam = prob_spam + log(self.spam_probs[index])\n","\n","      if prob_spam >= prob_ham:\n","        return 1\n","      else:\n","        return 0\n","\n","    def tokenize(self, doc):\n","        stemmer = Stemmer()\n","        tokens = re.findall(r'\\b\\w+\\b', doc.lower())\n","        if self.stop_words:\n","            tokens = [stemmer.stem(t) for t in tokens if t not in self.stop_words]\n","        return np.unique(tokens)\n","\n"],"metadata":{"id":"sUkipWwxmicD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data, test_data, total_prob_ham, total_prob_spam = process_mix(0.8)"],"metadata":{"id":"ULPYcZqCmmAl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = NB_Classifier(train_data, test_data)"],"metadata":{"id":"-VpRzYkwfkUj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.train()"],"metadata":{"id":"JAY3SntHag3w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.test()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Hj5KmS6iuBO","executionInfo":{"status":"ok","timestamp":1725377578547,"user_tz":-330,"elapsed":103336,"user":{"displayName":"Raj Vishwakarma","userId":"08775079886412699309"}},"outputId":"2b8cba3a-ef40-4519-91a4-f04c9e2be9d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[7880 1418]\n"," [  25 7367]]\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('Colab Notebooks')"],"metadata":{"id":"8bf2qnP4XpMp","executionInfo":{"status":"ok","timestamp":1728481915198,"user_tz":-330,"elapsed":517,"user":{"displayName":"Raj Vishwakarma","userId":"08775079886412699309"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gUmXf8D2BdPv","executionInfo":{"status":"ok","timestamp":1728481918409,"user_tz":-330,"elapsed":420,"user":{"displayName":"Raj Vishwakarma","userId":"08775079886412699309"}},"outputId":"45d0d2e1-fa75-476a-a788-7bb33366b6dc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["logistic-filter.ipynb\t    spam-filter.ipynb  svm-spam.ipynb\tUntitled1.ipynb\n","logistic-spam-filter.ipynb  svm-filter\t       Untitled0.ipynb\n"]}]}]}